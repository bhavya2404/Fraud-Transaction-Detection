# -*- coding: utf-8 -*-
"""CREDIT CARD FRAUD DETICTION.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Z1FH109dgrnDJsU1X5mmUX-5QrjNaEzM

IMPORT ALL REQUIRED PACKAGES
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from imblearn.over_sampling import RandomOverSampler

"""LOAD THE DATA SET"""

credit=pd.read_csv('creditcard.csv')

credit.shape

credit.info()

credit.describe()

credit.head()

"""CLEANING THE DATA"""

credit.drop_duplicates(inplace=True)

credit.fillna('NaN', inplace=True)

mean_amount = credit['Amount'].mean()
std_amount = credit['Amount'].std()
credit= credit[(credit['Amount'] >= mean_amount - 3 * std_amount) & (credit['Amount'] <= mean_amount + 3 * std_amount)]

credit.shape

credit.describe()

"""DATA PREPROCESSING"""

scaler = StandardScaler()
credit['scaled_amount'] = scaler.fit_transform(credit['Amount'].values.reshape(-1, 1))
credit['scaled_time'] = scaler.fit_transform(credit['Time'].values.reshape(-1, 1))

credit.drop(['Time', 'Amount'], axis=1, inplace=True)

X = credit.drop('Class', axis=1)
y = credit['Class']

credit.hist(figsize=(15, 10))
plt.show()

import math
n_features = len(credit.columns)
layout_rows = math.ceil(math.sqrt(n_features))
layout_cols = math.ceil(n_features / layout_rows)
credit.plot(kind='density', subplots=True, layout=(layout_rows, layout_cols), sharex=False, figsize=(15, 10))
plt.show()

sns.countplot(data=credit, x='Class')
plt.title('Class Distribution')
plt.show()

correlation_matrix = credit.corr()
plt.figure(figsize=(12, 8))
sns.heatmap(correlation_matrix, annot=False, cmap='coolwarm')
plt.title('Feature Correlation Heatmap')
plt.show()

plt.figure(figsize=(15, 10))
sns.boxplot(data=credit, orient="h")
plt.title('Box Plot of Features')
plt.show()

credit['TransactionHour'] = credit['scaled_time'].apply(lambda x: int(x * 24))
df_agg = credit.groupby('TransactionHour')['scaled_amount'].mean().reset_index()

plt.figure(figsize=(12, 6))
plt.plot(df_agg['TransactionHour'], df_agg['scaled_amount'],  linestyle='-')
plt.xlabel('Time (Hour of the Day)')
plt.ylabel('Average Scaled Amount')
plt.title('Time Series Plot of Transaction Amount')
plt.show()

"""TRAINING THE DATA SET"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
oversampler = RandomOverSampler(sampling_strategy=0.5)
X_resampled, y_resampled = oversampler.fit_resample(X_train, y_train)

X_train

y_train

X_test

y_test

rf_classifier = RandomForestClassifier(n_estimators=10, random_state=42)
rf_classifier.fit(X_resampled, y_resampled)
y_pred = rf_classifier.predict(X_test)

"""EVALUATING THE MODEL"""

print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))

print("\nClassification Report:")
print(classification_report(y_test, y_pred))

print("\nAccuracy Score:")
print(accuracy_score(y_test, y_pred))

"""VISUALIZING THE MODEL"""

cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, cmap="Blues", fmt="d")
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

feature_importance = rf_classifier.feature_importances_
feature_names = X.columns
plt.figure(figsize=(12, 6))
sns.barplot(x=feature_importance, y=feature_names)
plt.title('Feature Importance')
plt.xlabel('Importance')
plt.ylabel('Feature Name')
plt.show()